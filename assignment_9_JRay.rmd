---
title: "Assignment 9"
output:
  word_document: default
  html_document: default
---
##Assignment 9
##For this assignment, you'll be using the lemons dataset, which is a subset of the dataset used for a Kaggle competition described here:   https://www.kaggle.com/c/DontGetKicked/data. Complete the following steps:
```{r}
library(tidyverse)
library(modelr)
library(knitr)
training <- read.csv("C:/Users/rayjm2/Desktop/Scripts/Week 9/training.csv", header=TRUE)
```



##  1. Using the lemons dataset, plot the probability of a car being a bad buy by make.

We always want to start with a cross tab of our dependent variable as a function of other variables. We structure cross tabs in a very particular way for the purposes of research: the independent variable goes on the rows, and the dependent variable goes on the columns. If proportions or percentages are going to be calculated, they should be calculated across rows. 

Recalling our previous lesson, let's look at a crosstab of `bad buy` with the independent variable of `make`

```{r}
tab_make<-with(training,table(Make,IsBadBuy))
```

If we want to make this a little better, we can change the row and column titles

```{r}
colnames(tab_make)<-c("Good Buy","Bad Buy")
kable(tab_make)
```

If we want to add proportions to this table, we can it like so:
```{r}
tab_make_prop<-prop.table(tab_make,margin=1)
kable(tab_make_prop)
```

Sometimes  (okay, all the times) audiences prefer percentages. Easy enough to do:
```{r}
kable(round(tab_make_prop*100,1))
```


##2. Create a table that shows the probability of a car being a bad buy by make.

## Bar Graphs from Cross Tabs

To format the data for barcharts, we make use of the concept of conditional means. Let's use two variables to calculate the probability of making a bad buy by make. 

```{r}
training_sum<-training%>%
  group_by(Make,IsBadBuy)%>%
  summarize(prob_IsBadBuy=mean(IsBadBuy,na.rm=TRUE))
```

Then we can plot this using our familiar ggplot commands:

```{r}
gg1<-ggplot(training_sum,aes(y=Make,x=Make,fill=IsBadBuy))
gg1<-gg1+geom_bar(stat="identity",position="dodge")
gg1<-gg1+xlab("Make")+ylab("BB(BadBuy)")
gg1<-gg1+theme(legend.title=element_blank())

gg1<-gg1+geom_text(aes(label=round(prob_IsBadBuy,2)),
                   position=position_dodge(width=.9),
                   vjust=-.25)
gg1
```


##3. Create a heatmap of the probability of a car being a bad buy by make and size of vehicle.

## Heat Maps

To generate a heat map, we'll first divide up the independent variables into quintiles:

```{r}
training<-training%>%mutate(VehicleAge_quintile=ntile(VehicleAge,5),
                WheelType_quintile=ntile(WheelTypeID,5))
```

Then we'll create a summary dataset that shows the probabilitie of the outcome across all of the combined categories of the two independent variables. 

```{R}
training_sum<-training%>%group_by(VehicleAge_quintile,WheelType_quintile)%>%
  summarize(prob_IsBadBuy=mean(IsBadBuy,na.rm=TRUE))%>%
  arrange(-prob_IsBadBuy)
```

Missing data isn't important, so we'll drop it. 

```{r}
training_sum<-training_sum%>%filter(!(is.na(VehicleAge_quintile)),!(is.na(WheelType_quintile)))
```

Now we're ready to plot!

```{r}
gg<-ggplot(training_sum,
           aes(x=as.factor(VehicleAge_quintile),
               y=as.factor(WheelType_quintile),fill=prob_IsBadBuy))
gg<-gg+geom_tile()
gg<-gg+scale_fill_gradient(low="white",high="red")
gg<-gg+xlab("VehicleAge")+ylab("WheelType")
gg<-gg+theme(legend.title=element_blank())
gg
```


##4. Create a plot of your choosing that shows the probability of a car being a bad buy by year and make.

```{r}
training<-training%>%mutate(VehYear_quintile=ntile(VehYear,5),
                Make_quintile=ntile(Make,5))
```

Then we'll create a summary dataset that shows the probabilitie of the outcome across all of the combined categories of the two independent variables. 

```{R}
training_sum<-training%>%group_by(VehYear_quintile,Make_quintile)%>%
  summarize(prob_IsBadBuy=mean(IsBadBuy,na.rm=TRUE))%>%
  arrange(-prob_IsBadBuy)
```

Missing data isn't important, so we'll drop it. 

```{r}
training_sum<-training_sum%>%filter(!(is.na(VehYear_quintile)),!(is.na(Make_quintile)))
```

Now we're ready to plot!

```{r}
gg<-ggplot(training_sum,
           aes(x=as.factor(VehYear_quintile),
               y=as.factor(Make_quintile),fill=prob_IsBadBuy))
gg<-gg+geom_tile()
gg<-gg+scale_fill_gradient(low="white",high="red")
gg<-gg+xlab("Vehicle Year")+ylab("Make")
gg<-gg+theme(legend.title=element_blank())
gg
```

